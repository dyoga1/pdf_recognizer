{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "EgXakhs3u6fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca100b3-9baf-428b-ee2c-7d3b004d0c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.15.116.90:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ],
      "source": [
        "# import tpu dlu\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "use_tpu = True #@param {type:\"boolean\"}\n",
        "\n",
        "if use_tpu:\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    TPU_ADDRESS = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "    TPU_ADDRESS = ''\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_ADDRESS)\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils -y\n",
        "!pip install pdf2image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6vYcWVkNRy2",
        "outputId": "10d1a9fe-7217-465c-f9a5-e1c18410fdbf"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import GlobalAveragePooling2D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
      ],
      "metadata": {
        "id": "DnvXJn9BNTgs"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define global variable\n",
        "image_height = 224\n",
        "image_width = 224"
      ],
      "metadata": {
        "id": "Rdto5iplaycx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_pdf_multipage(pdf_path):\n",
        "    # Convert PDF to images\n",
        "    images = convert_from_path(pdf_path, dpi=20)\n",
        "    resized_images = []\n",
        "    for image in images:\n",
        "        resized_image = image.resize((image_width, image_height))\n",
        "        resized_images.append(resized_image)\n",
        "    return resized_images\n",
        "\n",
        "def preprocess_pdf_singlepage(pdf_path):\n",
        "    image = convert_from_path(pdf_path, dpi=20)[0]\n",
        "    resized_image = image.resize((image_width, image_height))\n",
        "    return resized_image\n",
        "\n",
        "def predict_pdf(pdf_path, model):\n",
        "    preprocessed_image = preprocess_pdf_singlepage(pdf_path)\n",
        "    image_array = np.array(preprocessed_image).reshape(-1,image_width, image_height,3)\n",
        "    prediction = model.predict(np.expand_dims(preprocessed_image, axis=0))\n",
        "    predicted_label = np.argmax(prediction)\n",
        "    return prediction\n",
        "\n",
        "def predict_pdf_multipage(pdf_path, model):\n",
        "    preprocessed_image = preprocess_pdf_multipage(pdf_path)\n",
        "    image_array = np.array(preprocessed_image)\n",
        "\n",
        "    page_result = []\n",
        "    for img in image_array:\n",
        "      prediction = model.predict(np.expand_dims(img, axis=0))\n",
        "      page_result.append(np.argmax(prediction))\n",
        "    return page_result\n",
        "\n",
        "def predict_image(preprocessed_image, model):\n",
        "    image_array = np.array(preprocessed_image).reshape(-1,image_width, image_height,3)\n",
        "    prediction = model.predict(np.expand_dims(preprocessed_image, axis=0))\n",
        "    predicted_label = np.argmax(prediction)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "qdGxXnn-Gea_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read excel train/test pdf dataset\n",
        "df = pd.read_excel(r'/content/drive/MyDrive/dataset/extract_dfp/dataset.xlsx',sheet_name=0)\n",
        "pdf_paths = df.path.to_list()\n",
        "labels = np.array(df.label.to_list())\n",
        "\n",
        "# read excel test data\n",
        "df = pd.read_excel(r'/content/drive/MyDrive/dataset/extract_dfp/dataset_test.xlsx',sheet_name=0)\n",
        "test_pdf_paths = df.path.to_list()\n",
        "test_labels = np.array(df.label.to_list())"
      ],
      "metadata": {
        "id": "CHYd3A7pMPA9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform train/val set\n",
        "\n",
        "# set number of training samples is the same as the number of PDF files\n",
        "num_samples = len(pdf_paths)\n",
        "num_channels = 3\n",
        "\n",
        "# Create zeros np array\n",
        "images = np.zeros((num_samples, image_height, image_width, num_channels))\n",
        "\n",
        "# change pdf to image\n",
        "for i, pdf_path in enumerate(pdf_paths):\n",
        "    resized_image = preprocess_pdf_singlepage(pdf_path)\n",
        "    image_array = np.array(resized_image)\n",
        "    images[i] = image_array\n",
        "\n",
        "# Verify the shape of the train_images dataset\n",
        "print(images.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsymTLiINCT2",
        "outputId": "768e7123-9a5a-4d7a-f032-8d0edac90472"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(468, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One Hot Encoding use scikit\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_label = oh_encoder.fit_transform(labels.reshape(-1,1))\n",
        "one_hot_labels = np.array(tf.constant(oh_label.toarray()))\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, one_hot_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verify the shapes of the training and validation sets\n",
        "print(\"Train Images Shape:\", train_images.shape)\n",
        "print(\"Train Labels Shape:\", train_labels.shape)\n",
        "print(\"Validation Images Shape:\", val_images.shape)\n",
        "print(\"Validation Labels Shape:\", val_labels.shape)\n",
        "\n",
        "print(\"label type:\", type(one_hot_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y68xCR7hmeEs",
        "outputId": "c0ac36a0-5bde-4064-de73-76dc302229c5"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images Shape: (374, 224, 224, 3)\n",
            "Train Labels Shape: (374, 3)\n",
            "Validation Images Shape: (94, 224, 224, 3)\n",
            "Validation Labels Shape: (94, 3)\n",
            "label type: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform test set\n",
        "\n",
        "# set number of training samples is the same as the number of PDF files\n",
        "test_num_samples = len(test_pdf_paths)\n",
        "num_channels = 3\n",
        "\n",
        "# Create zeros np array\n",
        "test_images = np.zeros((test_num_samples, image_height, image_width, num_channels))\n",
        "\n",
        "# change pdf to image\n",
        "for i, pdf_path in enumerate(test_pdf_paths):\n",
        "    resized_image = preprocess_pdf_singlepage(pdf_path)\n",
        "    image_array = np.array(resized_image)\n",
        "    test_images[i] = image_array\n",
        "\n",
        "# Verify the shape of the train_images dataset\n",
        "print(test_images.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZSp0v6e_tgF",
        "outputId": "a7ba328c-d9f8-4a07-c529-ade4952d5305"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding on the encoded labels\n",
        "test_oh_label = oh_encoder.transform(test_labels.reshape(-1,1))\n",
        "test_oh_label_tf = np.array(tf.constant(test_oh_label.toarray()))\n",
        "\n",
        "# Verify the shapes of the training and validation sets\n",
        "print(\"Test Labels Shape:\", test_oh_label_tf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NH-XEVuIiG5",
        "outputId": "625d308c-546a-4065-8be7-8480dfdad4ff"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Labels Shape: (22, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained VGG16 model (excluding the top fully-connected layers)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
        "\n",
        "# Freeze the weights of the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add new classification layers on top of the base model\n",
        "x = base_model.output\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Output layer\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "# test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "# print(\"Test Loss:\", test_loss)\n",
        "# print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFH9DZmdP9m2",
        "outputId": "fb0ec009-5d52-4819-c852-d325001ac6d9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 7s 542ms/step - loss: 8.0219 - accuracy: 0.7567 - val_loss: 0.7353 - val_accuracy: 0.9255\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 5s 461ms/step - loss: 1.4948 - accuracy: 0.9251 - val_loss: 0.5843 - val_accuracy: 0.9468\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 5s 459ms/step - loss: 0.5219 - accuracy: 0.9599 - val_loss: 0.0972 - val_accuracy: 0.9681\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 5s 461ms/step - loss: 0.5192 - accuracy: 0.9679 - val_loss: 0.1585 - val_accuracy: 0.9894\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 5s 457ms/step - loss: 0.0393 - accuracy: 0.9866 - val_loss: 0.1584 - val_accuracy: 0.9787\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 5s 459ms/step - loss: 0.0923 - accuracy: 0.9840 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 5s 463ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.1194 - val_accuracy: 0.9894\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 5s 463ms/step - loss: 0.0050 - accuracy: 0.9973 - val_loss: 0.2530 - val_accuracy: 0.9787\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 5s 460ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.1976 - val_accuracy: 0.9787\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 6s 469ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.0975 - val_accuracy: 0.9681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa28bf72ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_oh_label_tf)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPHSZPOEqI4a",
        "outputId": "3771aa81-c521-4c92-8b14-d140d6b481cd"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 354ms/step - loss: 2.7400e-05 - accuracy: 1.0000\n",
            "Test Loss: 2.739954652497545e-05\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(r'/content/drive/MyDrive/dataset/extract_dfp/model.h5')"
      ],
      "metadata": {
        "id": "SyeCInMSl5_Q"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phi5IJUkK09Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}